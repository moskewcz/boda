CUCL_GLOBAL_KERNEL void %(rtc_func_name)( GASQ float const * const filts, // CUCL IN out_chan_blk:in_chan:y:x:out_chan_reg:out_chan_tile
					  GASQ float const * const biases, // CUCL IN out_chan
					  GASQ float const * const in, // CUCL IN blk:blk_iter:blk_iter_chan:blk_pel
					  GASQ float * const out, // CUCL OUT img:chan:y:x
					  GASQ float * const out_xp ) // CUCL OUT blk:blk_iter:blk_iter_chan:blk_pel
/* work */  // CUCL REF pels_blk:out_chan_blk:pels_tile:out_chan_tile:pels:out_chan
{
  // note: only one of out/out_xp will be non-null and used below ...
  // CUCL IX out_pel out use_dims=img:y:x 
  // CUCL IX GRP_ID_1D work use_dims=pels_blk:out_chan_blk
  // CUCL IX LOC_ID_1D work use_dims=pels_tile:out_chan_tile
  // note: <each thread handles> work use_dims=pels:out_chan; with pels_sz==out_chan_sz==t_tile_sz (currently); loops over in.chan==filts.in_chan
  // note: for k1conv we have filts_y_dim==filts_x_dim==1
  // refactoring note: blk_filt_ix_sz --> %(filts_x_sz) == (number of output chans handled by this block) (also == %(filts_y_sz) and %(filts_in_chan_sz))
  // refactoring note: in_chan_tile --> %(in_blk_iter_chan_dim) 
  // note: all_smem_sz is max(filts+in,out) == max((%(filts_in_chan_sz)*%(in_blk_iter_chan_dim))+%(in_blk_iter_sz),%(out_smem_sz))
  LOCSHAR_MEM float all_smem[%(all_smem_sz)]; 
  LSMASQ float * const filts_smem = all_smem;
  LSMASQ float * const in_smem = filts_smem + %(filts_in_chan_sz)*%(in_blk_iter_chan_dim) // aka "+ filts_smem_sz"

  float out_tile[%(work_pels_dim)*%(work_out_chan_dim)] = {0}; // tile of output for this thread to compute, stored in registers
  // reg. buffers for one strip each from in and filts, for the same filts_ix_out_chan_elem
  float filts_strip[%(work_out_chan_dim)]; // across output chans (stride is blk_filt_ix_sz )
  float in_strip[%(work_pels_dim)]; // across pels (approx square block in x/y space, favoring x if sqrt() not integer)

  int32_t const blk_filt_ix_base = %(GRP_ID_1D_out_chan_blk)*%(filts_out_chan_blk_sz); // index of first out chan
  int32_t blk_in_ix_base = %(GRP_ID_1D_pels_blk)*%(in_blk_sz) + LOC_ID_1D;// index of first input pel to load for this thread

  LSMASQ float * const filts_smem_off = filts_smem + %(LOC_ID_1D_out_chan_tile);
  LSMASQ float * const in_smem_off = in_smem + %(LOC_ID_1D_pels_tile)*%(work_pels_dim);
  LSMASQ float * const out_smem_off = all_smem + LOC_ID_1D;
  int32_t filts_off = blk_filt_ix_base + LOC_ID_1D;
  // iteratate over filter elements
  for( int32_t blk_iter = 0; blk_iter != %(in_blk_iter_dim); ++blk_iter ) {
    BARRIER_SYNC;
    %(smem_loads);
    BARRIER_SYNC;
    filts_off += %(filts_in_chan_sz)*%(in_blk_iter_chan_dim));
    blk_in_ix_base += %(in_blk_iter_sz);
    %(inner_loop_body);
  }
  // load per-block biases into smem
  if( flags == 2 ) { return; }
  BARRIER_SYNC;
  for( int32_t i = 0; i != %(out_chan_bias_smem_load_iter); ++i ) {
    int32_t const t_smem_bias_ix = LOC_ID_1D+%(tpb)*i;
    if( t_smem_bias_ix < %(filts_x_sz) ) { 
      int32_t const ocix_base = %(GRP_ID_1D_out_chan_blk)*%(filts_x_sz);
      int32_t const load_reg = t_smem_bias_ix / %(work_out_chan_tile_dim);
      int32_t const load_tile = t_smem_bias_ix %% %(work_out_chan_tile_dim);
      int32_t const ocix = ocix_base + load_tile*%(work_out_chan_dim) + load_reg;
      if( ocix < %(biases_out_chan_dim) ) { filts_smem[t_smem_bias_ix] = biases[ ocix ]; }
    }
  }
  BARRIER_SYNC;
  // load biases into filts_strip
  %(t_tile_bias_loads);
  if( flags == 1 ) { 
    GASQ float * const out_off = out + LOC_ID_1D;
    %(t_tile_dummy_stores);
    return; 
  }
  // add bias to each elem of out_tile[] and store the results to out[]
  %(t_tile_stores);
}

